<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ML Framework Storage Patterns - Deep Dive</title>
    <style>
        :root {
            --bg-primary: #0a0a0f;
            --bg-secondary: #12121a;
            --bg-tertiary: #1a1a25;
            --text-primary: #e0e0e0;
            --text-secondary: #a0a0a0;
            --accent-blue: #4a9eff;
            --accent-green: #4ade80;
            --accent-yellow: #fbbf24;
            --accent-red: #f87171;
            --accent-purple: #a78bfa;
            --accent-cyan: #22d3ee;
            --border-color: #2a2a3a;
            --code-bg: #1e1e2e;
        }
        
        * { margin: 0; padding: 0; box-sizing: border-box; }
        
        body {
            font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: var(--bg-primary);
            color: var(--text-primary);
            line-height: 1.7;
            padding: 40px 20px;
        }
        
        .container { max-width: 1400px; margin: 0 auto; }
        
        .nav-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            padding: 20px 30px;
            background: var(--bg-secondary);
            border-radius: 12px;
            margin-bottom: 40px;
            border: 1px solid var(--border-color);
        }
        
        .nav-header a {
            color: var(--accent-blue);
            text-decoration: none;
            padding: 8px 16px;
            border-radius: 6px;
            transition: all 0.2s;
        }
        
        .nav-header a:hover { background: var(--bg-tertiary); }
        
        .hero {
            text-align: center;
            padding: 60px 20px;
            background: linear-gradient(135deg, var(--bg-secondary) 0%, var(--bg-tertiary) 100%);
            border-radius: 16px;
            margin-bottom: 50px;
            border: 1px solid var(--border-color);
        }
        
        .hero h1 {
            font-size: 2.5rem;
            margin-bottom: 15px;
            background: linear-gradient(135deg, var(--accent-green), var(--accent-cyan));
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
        }
        
        .hero p { font-size: 1.2rem; color: var(--text-secondary); max-width: 800px; margin: 0 auto; }
        
        .section {
            background: var(--bg-secondary);
            border-radius: 16px;
            padding: 40px;
            margin-bottom: 40px;
            border: 1px solid var(--border-color);
        }
        
        .section-title {
            font-size: 1.8rem;
            margin-bottom: 25px;
            color: var(--accent-blue);
            display: flex;
            align-items: center;
            gap: 12px;
        }
        
        .subsection-title {
            font-size: 1.4rem;
            margin: 30px 0 20px 0;
            color: var(--accent-green);
            border-left: 4px solid var(--accent-green);
            padding-left: 15px;
        }
        
        p { margin-bottom: 15px; color: var(--text-secondary); }
        
        .info-box {
            padding: 20px 25px;
            border-radius: 10px;
            margin: 20px 0;
        }
        
        .info-box.critical {
            background: rgba(248, 113, 113, 0.1);
            border-left: 4px solid var(--accent-red);
        }
        
        .info-box.success {
            background: rgba(74, 222, 128, 0.1);
            border-left: 4px solid var(--accent-green);
        }
        
        .info-box.warning {
            background: rgba(251, 191, 36, 0.1);
            border-left: 4px solid var(--accent-yellow);
        }
        
        .info-box.insight {
            background: rgba(74, 158, 255, 0.1);
            border-left: 4px solid var(--accent-blue);
        }
        
        pre {
            background: var(--code-bg);
            border-radius: 10px;
            padding: 20px;
            overflow-x: auto;
            margin: 20px 0;
            border: 1px solid var(--border-color);
        }
        
        code {
            font-family: 'JetBrains Mono', 'Fira Code', monospace;
            font-size: 0.9rem;
            line-height: 1.6;
        }
        
        .inline-code {
            background: var(--bg-tertiary);
            padding: 2px 8px;
            border-radius: 4px;
            font-family: 'JetBrains Mono', monospace;
            font-size: 0.85em;
            color: var(--accent-cyan);
        }
        
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
            font-size: 0.95rem;
        }
        
        th, td {
            padding: 14px 16px;
            text-align: left;
            border-bottom: 1px solid var(--border-color);
        }
        
        th {
            background: var(--bg-tertiary);
            color: var(--accent-blue);
            font-weight: 600;
            text-transform: uppercase;
            font-size: 0.8rem;
        }
        
        tr:hover { background: var(--bg-tertiary); }
        
        .good { color: var(--accent-green); font-weight: 600; }
        .medium { color: var(--accent-yellow); font-weight: 600; }
        .poor { color: var(--accent-red); font-weight: 600; }
        
        .cards-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(320px, 1fr));
            gap: 25px;
            margin: 25px 0;
        }
        
        .card {
            background: var(--bg-tertiary);
            border-radius: 12px;
            padding: 25px;
            border: 1px solid var(--border-color);
        }
        
        .card-header {
            display: flex;
            justify-content: space-between;
            align-items: flex-start;
            margin-bottom: 15px;
        }
        
        .card-title { font-size: 1.1rem; color: var(--text-primary); }
        
        .card-badge {
            padding: 4px 10px;
            border-radius: 12px;
            font-size: 0.75rem;
            font-weight: 600;
        }
        
        .badge-production { background: rgba(74, 222, 128, 0.2); color: var(--accent-green); }
        .badge-critical { background: rgba(248, 113, 113, 0.2); color: var(--accent-red); }
        
        .architecture-diagram {
            background: var(--bg-tertiary);
            border-radius: 12px;
            padding: 30px;
            margin: 25px 0;
            font-family: 'JetBrains Mono', monospace;
            font-size: 0.85rem;
            overflow-x: auto;
            border: 1px solid var(--border-color);
        }
        
        .comparison {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 25px;
            margin: 25px 0;
        }
        
        .comparison-side {
            background: var(--bg-tertiary);
            border-radius: 12px;
            padding: 25px;
            border: 1px solid var(--border-color);
        }
    </style>
</head>
<body>
    <div class="container">
        <nav class="nav-header">
            <a href="10_expert_storage_guide.html">&larr; Expert Guide</a>
            <span style="color: var(--text-secondary);">ML Framework Storage Patterns</span>
            <a href="index.html">Home &rarr;</a>
        </nav>

        <div class="hero">
            <h1>ML Framework Storage Patterns</h1>
            <p>Deep-dive into how PyTorch, TensorFlow, JAX, DeepSpeed, and Megatron-LM interact with storage.
            Real configurations from production LLM training pipelines.</p>
        </div>

        <!-- DeepSpeed Deep Dive -->
        <section class="section">
            <h2 class="section-title">DeepSpeed Storage Deep Dive</h2>
            
            <div class="info-box critical">
                <strong>üö® Why DeepSpeed Matters:</strong> If you're training models over 10B parameters, 
                you're almost certainly using DeepSpeed (or FSDP). DeepSpeed's ZeRO (Zero Redundancy Optimizer) 
                stages fundamentally change how storage is accessed. Understanding this is essential.
            </div>

                        <h3 class="subsection-title">ZeRO Stages and Storage Impact</h3>
            
            <div class="arch-diagram">
                <div class="arch-title">DeepSpeed ZeRO Memory Hierarchy</div>
                <svg viewBox="0 0 800 300" style="width: 100%; max-width: 800px; margin: 20px auto; display: block; background: #0a0a12; border-radius: 8px;">
                    <!-- Title -->
                    <text x="400" y="25" fill="#00d4ff" font-size="13" font-weight="bold" text-anchor="middle" font-family="sans-serif">Model Training State</text>
                    
                    <!-- Main container -->
                    <rect x="20" y="35" width="760" height="150" rx="8" fill="#1a1a28" stroke="#3b82f6" stroke-width="2"/>
                    
                    <!-- Parameters box -->
                    <rect x="40" y="55" width="200" height="80" rx="6" fill="#0a0a12" stroke="#00ff88" stroke-width="2"/>
                    <text x="140" y="80" fill="#00ff88" font-size="11" font-weight="bold" text-anchor="middle" font-family="sans-serif">Parameters (P)</text>
                    <text x="140" y="100" fill="#888" font-size="9" text-anchor="middle" font-family="sans-serif">~4B per 1B params</text>
                    <text x="140" y="120" fill="#fbbf24" font-size="10" text-anchor="middle" font-family="sans-serif">70B Model: 280 GB</text>
                    
                    <!-- Gradients box -->
                    <rect x="280" y="55" width="200" height="80" rx="6" fill="#0a0a12" stroke="#a855f7" stroke-width="2"/>
                    <text x="380" y="80" fill="#a855f7" font-size="11" font-weight="bold" text-anchor="middle" font-family="sans-serif">Gradients (G)</text>
                    <text x="380" y="100" fill="#888" font-size="9" text-anchor="middle" font-family="sans-serif">~4B per 1B params</text>
                    <text x="380" y="120" fill="#fbbf24" font-size="10" text-anchor="middle" font-family="sans-serif">70B Model: 280 GB</text>
                    
                    <!-- Optimizer State box -->
                    <rect x="520" y="55" width="240" height="80" rx="6" fill="#0a0a12" stroke="#ef4444" stroke-width="2"/>
                    <text x="640" y="80" fill="#ef4444" font-size="11" font-weight="bold" text-anchor="middle" font-family="sans-serif">Optimizer State (OS)</text>
                    <text x="640" y="100" fill="#888" font-size="9" text-anchor="middle" font-family="sans-serif">~12B per 1B (Adam: m,v,master)</text>
                    <text x="640" y="120" fill="#fbbf24" font-size="10" text-anchor="middle" font-family="sans-serif">70B Model: 840 GB</text>
                    
                    <!-- Total -->
                    <text x="400" y="170" fill="#ff6b6b" font-size="13" font-weight="bold" text-anchor="middle" font-family="sans-serif">Total: ~1.4 TB per GPU!</text>
                    
                    <!-- ZeRO Stages -->
                    <text x="50" y="215" fill="#fbbf24" font-size="11" font-weight="bold" font-family="sans-serif">ZeRO Stages:</text>
                    <text x="50" y="235" fill="#00ff88" font-size="9" font-family="sans-serif">ZeRO-1: Partition OS across GPUs &#8594; OS per GPU: 840/N GB</text>
                    <text x="50" y="252" fill="#00ff88" font-size="9" font-family="sans-serif">ZeRO-2: Partition OS + G &#8594; (OS+G) per GPU: 1120/N GB</text>
                    <text x="50" y="269" fill="#00ff88" font-size="9" font-family="sans-serif">ZeRO-3: Partition OS + G + P &#8594; Total per GPU: 1400/N GB</text>
                    
                    <text x="450" y="269" fill="#ef4444" font-size="10" font-weight="bold" font-family="sans-serif">ZeRO-Offload/Infinity: GPU exhausted &#8594; Offload to NVMe</text>
                </svg>
            </div>

            <pre><code><span style="color: #6a9955;"># Complete DeepSpeed configuration for 70B model training</span>
<span style="color: #6a9955;"># with NVMe offload - production tested</span>

<span style="color: #6a9955;"># ds_config_70b.json</span>
{
    <span style="color: #ce9178;">"train_batch_size"</span>: <span style="color: #b5cea8;">2048</span>,
    <span style="color: #ce9178;">"train_micro_batch_size_per_gpu"</span>: <span style="color: #b5cea8;">2</span>,
    <span style="color: #ce9178;">"gradient_accumulation_steps"</span>: <span style="color: #b5cea8;">128</span>,
    
    <span style="color: #ce9178;">"zero_optimization"</span>: {
        <span style="color: #ce9178;">"stage"</span>: <span style="color: #b5cea8;">3</span>,
        
        <span style="color: #6a9955;">// Offload optimizer states to NVMe</span>
        <span style="color: #ce9178;">"offload_optimizer"</span>: {
            <span style="color: #ce9178;">"device"</span>: <span style="color: #ce9178;">"nvme"</span>,
            <span style="color: #ce9178;">"nvme_path"</span>: <span style="color: #ce9178;">"/mnt/nvme_raid0"</span>,
            <span style="color: #ce9178;">"buffer_count"</span>: <span style="color: #b5cea8;">5</span>,
            <span style="color: #ce9178;">"buffer_size"</span>: <span style="color: #b5cea8;">2147483648</span>,  <span style="color: #6a9955;">// 2GB buffers</span>
            <span style="color: #ce9178;">"fast_init"</span>: <span style="color: #569cd6;">true</span>,
            <span style="color: #ce9178;">"pin_memory"</span>: <span style="color: #569cd6;">true</span>
        },
        
        <span style="color: #6a9955;">// Offload parameters to NVMe (for very large models)</span>
        <span style="color: #ce9178;">"offload_param"</span>: {
            <span style="color: #ce9178;">"device"</span>: <span style="color: #ce9178;">"nvme"</span>,
            <span style="color: #ce9178;">"nvme_path"</span>: <span style="color: #ce9178;">"/mnt/nvme_raid0"</span>,
            <span style="color: #ce9178;">"buffer_count"</span>: <span style="color: #b5cea8;">5</span>,
            <span style="color: #ce9178;">"buffer_size"</span>: <span style="color: #b5cea8;">2147483648</span>,
            <span style="color: #ce9178;">"max_in_cpu"</span>: <span style="color: #b5cea8;">10000000000</span>  <span style="color: #6a9955;">// 10GB CPU buffer first</span>
        },
        
        <span style="color: #6a9955;">// Async I/O configuration - CRITICAL for performance</span>
        <span style="color: #ce9178;">"aio"</span>: {
            <span style="color: #ce9178;">"block_size"</span>: <span style="color: #b5cea8;">1048576</span>,     <span style="color: #6a9955;">// 1MB blocks (NVMe optimal)</span>
            <span style="color: #ce9178;">"queue_depth"</span>: <span style="color: #b5cea8;">32</span>,         <span style="color: #6a9955;">// Match SSD queue depth</span>
            <span style="color: #ce9178;">"thread_count"</span>: <span style="color: #b5cea8;">8</span>,         <span style="color: #6a9955;">// Parallel I/O threads</span>
            <span style="color: #ce9178;">"single_submit"</span>: <span style="color: #569cd6;">false</span>,    <span style="color: #6a9955;">// Batch submissions</span>
            <span style="color: #ce9178;">"overlap_events"</span>: <span style="color: #569cd6;">true</span>,    <span style="color: #6a9955;">// Async overlap</span>
            <span style="color: #ce9178;">"use_gds"</span>: <span style="color: #569cd6;">true</span>            <span style="color: #6a9955;">// Enable GPUDirect Storage!</span>
        },
        
        <span style="color: #6a9955;">// Memory optimization</span>
        <span style="color: #ce9178;">"contiguous_gradients"</span>: <span style="color: #569cd6;">true</span>,
        <span style="color: #ce9178;">"overlap_comm"</span>: <span style="color: #569cd6;">true</span>,
        <span style="color: #ce9178;">"reduce_scatter"</span>: <span style="color: #569cd6;">true</span>,
        <span style="color: #ce9178;">"reduce_bucket_size"</span>: <span style="color: #b5cea8;">500000000</span>,
        <span style="color: #ce9178;">"allgather_bucket_size"</span>: <span style="color: #b5cea8;">500000000</span>
    },
    
    <span style="color: #ce9178;">"checkpoint"</span>: {
        <span style="color: #ce9178;">"tag_validation"</span>: <span style="color: #ce9178;">"warn"</span>,
        <span style="color: #ce9178;">"load_universal"</span>: <span style="color: #569cd6;">true</span>,
        <span style="color: #ce9178;">"use_node_local_storage"</span>: <span style="color: #569cd6;">true</span>,
        <span style="color: #ce9178;">"parallel_write"</span>: {
            <span style="color: #ce9178;">"pipeline_read"</span>: <span style="color: #569cd6;">true</span>,
            <span style="color: #ce9178;">"pipeline_write"</span>: <span style="color: #569cd6;">true</span>
        }
    },
    
    <span style="color: #ce9178;">"fp16"</span>: {
        <span style="color: #ce9178;">"enabled"</span>: <span style="color: #569cd6;">true</span>,
        <span style="color: #ce9178;">"loss_scale"</span>: <span style="color: #b5cea8;">0</span>,
        <span style="color: #ce9178;">"loss_scale_window"</span>: <span style="color: #b5cea8;">1000</span>
    }
}</code></pre>

            <h3 class="subsection-title">Storage Requirements by Model Size</h3>
            
            <table>
                <thead>
                    <tr>
                        <th>Model Size</th>
                        <th>ZeRO Stage</th>
                        <th>NVMe Capacity Needed</th>
                        <th>NVMe Bandwidth Needed</th>
                        <th>Checkpoint Size</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><strong>7B (LLaMA)</strong></td>
                        <td>ZeRO-2</td>
                        <td class="good">~100 GB</td>
                        <td class="good">2-3 GB/s</td>
                        <td>~14 GB</td>
                    </tr>
                    <tr>
                        <td><strong>13B</strong></td>
                        <td>ZeRO-2/3</td>
                        <td class="good">~200 GB</td>
                        <td class="medium">3-5 GB/s</td>
                        <td>~26 GB</td>
                    </tr>
                    <tr>
                        <td><strong>33B</strong></td>
                        <td>ZeRO-3</td>
                        <td class="medium">~500 GB</td>
                        <td class="medium">5-8 GB/s</td>
                        <td>~66 GB</td>
                    </tr>
                    <tr>
                        <td><strong>65B/70B</strong></td>
                        <td>ZeRO-3 + Offload</td>
                        <td class="poor">~2 TB</td>
                        <td class="poor">8-12 GB/s</td>
                        <td>~140 GB</td>
                    </tr>
                    <tr>
                        <td><strong>175B (GPT-3 scale)</strong></td>
                        <td>ZeRO-Infinity</td>
                        <td class="poor">~5 TB</td>
                        <td class="poor">15+ GB/s</td>
                        <td>~350 GB</td>
                    </tr>
                    <tr>
                        <td><strong>540B (PaLM scale)</strong></td>
                        <td>ZeRO-Infinity</td>
                        <td class="poor">~15 TB</td>
                        <td class="poor">25+ GB/s</td>
                        <td>~1 TB</td>
                    </tr>
                </tbody>
            </table>

            <h3 class="subsection-title">DeepSpeed NVMe Filesystem Setup</h3>
            
            <pre><code><span style="color: #6a9955;"># Optimal filesystem configuration for DeepSpeed NVMe offload</span>

<span style="color: #6a9955;"># 1. Create RAID0 across all NVMe drives</span>
<span style="color: #6a9955;"># Assuming 8x NVMe drives for H100 node</span>
sudo mdadm --create /dev/md0 --level=0 --raid-devices=8 \
    /dev/nvme0n1 /dev/nvme1n1 /dev/nvme2n1 /dev/nvme3n1 \
    /dev/nvme4n1 /dev/nvme5n1 /dev/nvme6n1 /dev/nvme7n1

<span style="color: #6a9955;"># 2. Format with XFS (better for large files than ext4)</span>
<span style="color: #6a9955;"># su/sw tuned for RAID stripe</span>
sudo mkfs.xfs -f -d su=1m,sw=8 -l su=1m /dev/md0

<span style="color: #6a9955;"># 3. Mount with optimal options</span>
sudo mkdir -p /mnt/nvme_raid0
sudo mount -o noatime,nodiratime,logbufs=8,logbsize=256k,allocsize=1g /dev/md0 /mnt/nvme_raid0

<span style="color: #6a9955;"># 4. Set permissions for training user</span>
sudo chown -R $USER:$USER /mnt/nvme_raid0

<span style="color: #6a9955;"># 5. Verify performance</span>
<span style="color: #6a9955;"># Sequential write (should be 50+ GB/s with 8 drives)</span>
fio --name=seq_write --ioengine=libaio --direct=1 --rw=write \
    --bs=1m --numjobs=8 --size=10G --directory=/mnt/nvme_raid0

<span style="color: #6a9955;"># 6. Pre-create DeepSpeed offload directory</span>
mkdir -p /mnt/nvme_raid0/deepspeed_offload
<span style="color: #6a9955;"># DeepSpeed will create files here during training</span>

<span style="color: #6a9955;"># /etc/fstab entry for persistence</span>
<span style="color: #6a9955;"># /dev/md0 /mnt/nvme_raid0 xfs noatime,nodiratime,logbufs=8 0 0</span></code></pre>

        </section>

        <!-- Megatron-LM Section -->
        <section class="section">
            <h2 class="section-title">Megatron-LM Storage Architecture</h2>
            
            <div class="info-box insight">
                <strong>‚Äô¬° Megatron Insight:</strong> Megatron-LM (NVIDIA's LLM framework) takes a different approach 
                than DeepSpeed. It uses memory-mapped files (<code class="inline-code">mmap</code>) for training data, 
                which leverages the kernel's page cache. This works well for sequential training access but requires 
                careful data preprocessing.
            </div>

                        <h3 class="subsection-title">Megatron Data Pipeline</h3>
            
            <div class="arch-diagram">
                <div class="arch-title">Megatron-LM Data Flow</div>
                <svg viewBox="0 0 800 340" style="width: 100%; max-width: 800px; margin: 20px auto; display: block; background: #0a0a12; border-radius: 8px;">
                    <!-- Data Preprocessing Section -->
                    <text x="400" y="22" fill="#00d4ff" font-size="11" font-weight="bold" text-anchor="middle" font-family="sans-serif">Data Preprocessing (Offline)</text>
                    <rect x="20" y="30" width="760" height="100" rx="6" fill="#1a1a28" stroke="#3b82f6" stroke-width="2"/>
                    
                    <!-- Raw Text -->
                    <rect x="40" y="50" width="130" height="50" rx="4" fill="#0a0a12" stroke="#888" stroke-width="1"/>
                    <text x="105" y="72" fill="#888" font-size="9" font-weight="bold" text-anchor="middle" font-family="sans-serif">Raw Text</text>
                    <text x="105" y="88" fill="#666" font-size="8" text-anchor="middle" font-family="monospace">corpus.json</text>
                    
                    <text x="190" y="75" fill="#00ff88" font-size="12" font-family="sans-serif">&#8594;</text>
                    
                    <!-- Tokenization -->
                    <rect x="210" y="50" width="130" height="50" rx="4" fill="#0a0a12" stroke="#a855f7" stroke-width="1"/>
                    <text x="275" y="72" fill="#a855f7" font-size="9" font-weight="bold" text-anchor="middle" font-family="sans-serif">Tokenization</text>
                    <text x="275" y="88" fill="#666" font-size="8" text-anchor="middle" font-family="monospace">GPT2 BPE</text>
                    
                    <text x="360" y="75" fill="#00ff88" font-size="12" font-family="sans-serif">&#8594;</text>
                    
                    <!-- Binary Format -->
                    <rect x="380" y="50" width="150" height="50" rx="4" fill="#0a0a12" stroke="#00ff88" stroke-width="1"/>
                    <text x="455" y="72" fill="#00ff88" font-size="9" font-weight="bold" text-anchor="middle" font-family="sans-serif">Binary Format</text>
                    <text x="455" y="88" fill="#666" font-size="8" text-anchor="middle" font-family="monospace">train.bin (mmap)</text>
                    
                    <text x="550" y="75" fill="#00ff88" font-size="12" font-family="sans-serif">&#8594;</text>
                    
                    <!-- Index File -->
                    <rect x="570" y="50" width="130" height="50" rx="4" fill="#0a0a12" stroke="#fbbf24" stroke-width="1"/>
                    <text x="635" y="72" fill="#fbbf24" font-size="9" font-weight="bold" text-anchor="middle" font-family="sans-serif">Index File</text>
                    <text x="635" y="88" fill="#666" font-size="8" text-anchor="middle" font-family="monospace">train.idx</text>
                    
                    <text x="400" y="122" fill="#888" font-size="8" text-anchor="middle" font-family="sans-serif">Key: .bin = memory-mapped | .idx = document boundaries</text>
                    
                    <!-- Arrow down -->
                    <text x="400" y="152" fill="#00ff88" font-size="14" font-family="sans-serif">&#8595;</text>
                    
                    <!-- Training Data Loading Section -->
                    <text x="400" y="175" fill="#00d4ff" font-size="11" font-weight="bold" text-anchor="middle" font-family="sans-serif">Training Data Loading</text>
                    <rect x="20" y="185" width="760" height="110" rx="6" fill="#1a1a28" stroke="#3b82f6" stroke-width="2"/>
                    
                    <!-- mmap -->
                    <rect x="60" y="205" width="170" height="60" rx="4" fill="#0a0a12" stroke="#fbbf24" stroke-width="2"/>
                    <text x="145" y="230" fill="#fbbf24" font-size="10" font-weight="bold" text-anchor="middle" font-family="sans-serif">mmap()</text>
                    <text x="145" y="248" fill="#666" font-size="8" text-anchor="middle" font-family="sans-serif">train.bin (NVMe)</text>
                    
                    <text x="250" y="235" fill="#00ff88" font-size="14" font-family="sans-serif">&#8594;</text>
                    
                    <!-- Page Cache -->
                    <rect x="280" y="205" width="170" height="60" rx="4" fill="#0a0a12" stroke="#a855f7" stroke-width="2"/>
                    <text x="365" y="230" fill="#a855f7" font-size="10" font-weight="bold" text-anchor="middle" font-family="sans-serif">Page Cache</text>
                    <text x="365" y="248" fill="#666" font-size="8" text-anchor="middle" font-family="sans-serif">Linux (DRAM)</text>
                    
                    <text x="470" y="235" fill="#00ff88" font-size="14" font-family="sans-serif">&#8594;</text>
                    
                    <!-- GPU Memory -->
                    <rect x="500" y="205" width="170" height="60" rx="4" fill="#0a0a12" stroke="#00ff88" stroke-width="2"/>
                    <text x="585" y="230" fill="#00ff88" font-size="10" font-weight="bold" text-anchor="middle" font-family="sans-serif">GPU Memory</text>
                    <text x="585" y="248" fill="#666" font-size="8" text-anchor="middle" font-family="sans-serif">Training Batch (HBM)</text>
                    
                    <!-- Bottom note -->
                    <text x="400" y="315" fill="#00ff88" font-size="10" text-anchor="middle" font-family="sans-serif">Sequential access = good prefetch = high throughput</text>
                </svg>
            </div>

            <pre><code><span style="color: #6a9955;"># Megatron-LM data preprocessing and training setup</span>

<span style="color: #6a9955;"># Step 1: Preprocess data into Megatron format</span>
python tools/preprocess_data.py \
    --input /data/raw/corpus.json \
    --output-prefix /nvme/megatron/gpt2_train \
    --vocab-file /models/gpt2-vocab.json \
    --merge-file /models/gpt2-merges.txt \
    --dataset-impl mmap \
    --tokenizer-type GPT2BPETokenizer \
    --workers 96 \
    --chunk-size 1000 \
    --append-eod

<span style="color: #6a9955;"># This creates:</span>
<span style="color: #6a9955;"># /nvme/megatron/gpt2_train_text_document.bin  (tokenized data)</span>
<span style="color: #6a9955;"># /nvme/megatron/gpt2_train_text_document.idx  (index)</span>

<span style="color: #6a9955;"># Step 2: Launch training with optimal I/O settings</span>
python -m torch.distributed.launch \
    --nproc_per_node 8 \
    --nnodes 4 \
    --node_rank $RANK \
    --master_addr $MASTER \
    --master_port 6000 \
    pretrain_gpt.py \
    --tensor-model-parallel-size 4 \
    --pipeline-model-parallel-size 2 \
    --num-layers 96 \
    --hidden-size 12288 \
    --num-attention-heads 96 \
    --seq-length 4096 \
    --max-position-embeddings 4096 \
    --micro-batch-size 1 \
    --global-batch-size 1024 \
    --train-iters 500000 \
    --data-path /nvme/megatron/gpt2_train_text_document \
    --data-impl mmap \
    --num-workers 4 \
    --checkpoint-activations \
    --save /checkpoints/gpt-70b \
    --save-interval 1000 \
    --async-save \
    --split 98,1,1

<span style="color: #6a9955;"># Storage recommendations for Megatron:</span>
<span style="color: #6a9955;"># 1. Put .bin files on fastest NVMe (mmap will use page cache)</span>
<span style="color: #6a9955;"># 2. Size system RAM to hold hot data (mmap benefits from cache)</span>
<span style="color: #6a9955;"># 3. Use RAID0 for checkpoints (write bandwidth matters)</span>
<span style="color: #6a9955;"># 4. Enable huge pages for large mmap regions</span>

<span style="color: #6a9955;"># Enable huge pages for better mmap performance</span>
sudo sysctl -w vm.nr_hugepages=4096  <span style="color: #6a9955;"># 8GB of huge pages</span>
echo "vm.nr_hugepages=4096" | sudo tee -a /etc/sysctl.conf</code></pre>

            <h3 class="subsection-title">Megatron vs DeepSpeed Storage Comparison</h3>
            
            <div class="comparison">
                <div class="comparison-side">
                    <h4 style="color: var(--accent-green);">Megatron-LM</h4>
                    <ul style="color: var(--text-secondary); padding-left: 20px;">
                        <li><strong>Data access:</strong> mmap (page cache)</li>
                        <li><strong>Best for:</strong> Sequential training data</li>
                        <li><strong>Checkpoint:</strong> Distributed per TP&times;PP rank</li>
                        <li><strong>NVMe role:</strong> Training data + checkpoints</li>
                        <li><strong>Memory pressure:</strong> Uses system RAM cache</li>
                        <li><strong>Pro:</strong> Simple, well-tested at scale</li>
                        <li><strong>Con:</strong> Less flexible than DeepSpeed</li>
                    </ul>
                </div>
                
                <div class="comparison-side">
                    <h4 style="color: var(--accent-blue);">DeepSpeed</h4>
                    <ul style="color: var(--text-secondary); padding-left: 20px;">
                        <li><strong>Data access:</strong> Direct I/O or GDS</li>
                        <li><strong>Best for:</strong> Memory-constrained training</li>
                        <li><strong>Checkpoint:</strong> Universal format, flexible</li>
                        <li><strong>NVMe role:</strong> Optimizer offload + checkpoints</li>
                        <li><strong>Memory pressure:</strong> Explicit offload control</li>
                        <li><strong>Pro:</strong> Train larger models with less GPU</li>
                        <li><strong>Con:</strong> More complex configuration</li>
                    </ul>
                </div>
            </div>

        </section>

        <!-- PyTorch FSDP Section -->
        <section class="section">
            <h2 class="section-title">‚Äù¬• PyTorch FSDP Storage Patterns</h2>
            
            <p>PyTorch's Fully Sharded Data Parallel (FSDP) is the native PyTorch answer to DeepSpeed ZeRO. 
            Understanding its storage patterns is essential for PyTorch-native training pipelines.</p>

            <h3 class="subsection-title">FSDP Checkpoint Strategies</h3>
            
            <pre><code><span style="color: #6a9955;"># PyTorch FSDP checkpoint with optimal storage configuration</span>
<span style="color: #c586c0;">import</span> torch
<span style="color: #c586c0;">from</span> torch.distributed.fsdp <span style="color: #c586c0;">import</span> (
    FullyShardedDataParallel <span style="color: #c586c0;">as</span> FSDP,
    StateDictType,
    FullStateDictConfig,
    ShardedStateDictConfig,
)
<span style="color: #c586c0;">from</span> torch.distributed.checkpoint <span style="color: #c586c0;">import</span> (
    FileSystemWriter,
    FileSystemReader,
    save,
    load,
)

<span style="color: #c586c0;">class</span> <span style="color: #4ec9b0;">FSDPCheckpointer</span>:
    <span style="color: #ce9178;">"""Optimized FSDP checkpointing for large models"""</span>
    
    <span style="color: #c586c0;">def</span> <span style="color: #dcdcaa;">__init__</span>(self, checkpoint_dir, model):
        self.checkpoint_dir = checkpoint_dir
        self.model = model
    
    <span style="color: #c586c0;">def</span> <span style="color: #dcdcaa;">save_sharded</span>(self, step, optimizer=<span style="color: #569cd6;">None</span>):
        <span style="color: #ce9178;">"""Fast sharded save - each rank saves its shard"""</span>
        
        <span style="color: #6a9955;"># Use sharded state dict (default in FSDP 2.0)</span>
        <span style="color: #c586c0;">with</span> FSDP.state_dict_type(
            self.model,
            StateDictType.SHARDED_STATE_DICT,
            ShardedStateDictConfig(offload_to_cpu=<span style="color: #569cd6;">True</span>)
        ):
            state_dict = {
                <span style="color: #ce9178;">'model'</span>: self.model.state_dict(),
                <span style="color: #ce9178;">'step'</span>: step,
            }
            <span style="color: #c586c0;">if</span> optimizer:
                state_dict[<span style="color: #ce9178;">'optimizer'</span>] = FSDP.optim_state_dict(
                    self.model, optimizer
                )
            
            <span style="color: #6a9955;"># Distributed save - each rank writes in parallel</span>
            save(
                state_dict,
                checkpoint_id=f<span style="color: #ce9178;">"{self.checkpoint_dir}/step_{step}"</span>,
                storage_writer=FileSystemWriter(
                    f<span style="color: #ce9178;">"{self.checkpoint_dir}/step_{step}"</span>,
                    single_file_per_rank=<span style="color: #569cd6;">True</span>,  <span style="color: #6a9955;"># Better I/O</span>
                    sync_files=<span style="color: #569cd6;">False</span>,  <span style="color: #6a9955;"># Async write</span>
                    thread_count=<span style="color: #b5cea8;">4</span>,  <span style="color: #6a9955;"># Parallel writes</span>
                )
            )
    
    <span style="color: #c586c0;">def</span> <span style="color: #dcdcaa;">save_consolidated</span>(self, step):
        <span style="color: #ce9178;">"""Slow but portable - full model on rank 0"""</span>
        
        <span style="color: #6a9955;"># Gather all shards to rank 0</span>
        <span style="color: #c586c0;">with</span> FSDP.state_dict_type(
            self.model,
            StateDictType.FULL_STATE_DICT,
            FullStateDictConfig(
                offload_to_cpu=<span style="color: #569cd6;">True</span>,
                rank0_only=<span style="color: #569cd6;">True</span>  <span style="color: #6a9955;"># Only rank 0 materializes</span>
            )
        ):
            <span style="color: #c586c0;">if</span> torch.distributed.get_rank() == <span style="color: #b5cea8;">0</span>:
                state_dict = self.model.state_dict()
                torch.save(
                    state_dict,
                    f<span style="color: #ce9178;">"{self.checkpoint_dir}/consolidated_step_{step}.pt"</span>
                )
        
        <span style="color: #6a9955;"># Barrier to ensure save completes</span>
        torch.distributed.barrier()

<span style="color: #6a9955;"># Usage pattern for training</span>
checkpointer = FSDPCheckpointer(<span style="color: #ce9178;">"/mnt/nvme/checkpoints"</span>, model)

<span style="color: #c586c0;">for</span> step, batch <span style="color: #c586c0;">in</span> enumerate(dataloader):
    loss = train_step(model, batch)
    
    <span style="color: #c586c0;">if</span> step % <span style="color: #b5cea8;">500</span> == <span style="color: #b5cea8;">0</span>:
        <span style="color: #6a9955;"># Fast sharded checkpoint for resume</span>
        checkpointer.save_sharded(step, optimizer)
    
    <span style="color: #c586c0;">if</span> step % <span style="color: #b5cea8;">5000</span> == <span style="color: #b5cea8;">0</span>:
        <span style="color: #6a9955;"># Slow consolidated checkpoint for export</span>
        checkpointer.save_consolidated(step)</code></pre>

        </section>

        <!-- Distributed Training I/O Patterns -->
        <section class="section">
            <h2 class="section-title">≈í¬ê Distributed Training I/O Patterns</h2>
            
            <h3 class="subsection-title">Data Parallel vs Model Parallel Storage</h3>
            
            <table>
                <thead>
                    <tr>
                        <th>Parallelism Type</th>
                        <th>Data Access Pattern</th>
                        <th>Storage Bottleneck</th>
                        <th>Optimization Strategy</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><strong>Data Parallel (DDP)</strong></td>
                        <td>Each GPU reads different data</td>
                        <td class="good">Embarrassingly parallel</td>
                        <td>Pre-shard data per rank</td>
                    </tr>
                    <tr>
                        <td><strong>Tensor Parallel (TP)</strong></td>
                        <td>All TP ranks read same data</td>
                        <td class="medium">Checkpoint consolidation</td>
                        <td>Rank 0 reads, broadcast</td>
                    </tr>
                    <tr>
                        <td><strong>Pipeline Parallel (PP)</strong></td>
                        <td>Stage 0 reads, others compute</td>
                        <td class="medium">Stage 0 bottleneck</td>
                        <td>Double buffering in stage 0</td>
                    </tr>
                    <tr>
                        <td><strong>FSDP/ZeRO</strong></td>
                        <td>All ranks read same batch</td>
                        <td class="poor">Checkpoint write amplification</td>
                        <td>Sharded checkpoints</td>
                    </tr>
                    <tr>
                        <td><strong>Expert Parallel (MoE)</strong></td>
                        <td>Random expert activation</td>
                        <td class="poor">Unpredictable access</td>
                        <td>Expert caching, prefetch</td>
                    </tr>
                </tbody>
            </table>

            <h3 class="subsection-title">Checkpoint Frequency Guidelines</h3>
            
            <pre><code><span style="color: #6a9955;"># Checkpoint frequency decision tree</span>

<span style="color: #c586c0;">def</span> <span style="color: #dcdcaa;">calculate_checkpoint_interval</span>(
    model_size_gb,
    training_throughput_samples_per_sec,
    checkpoint_bandwidth_gb_per_sec,
    acceptable_rework_hours=<span style="color: #b5cea8;">0.5</span>
):
    <span style="color: #ce9178;">"""
    Calculate optimal checkpoint interval based on:
    - Time to save checkpoint
    - Cost of rework if crash happens
    - Training throughput
    """</span>
    
    <span style="color: #6a9955;"># Time to write checkpoint</span>
    checkpoint_time_seconds = model_size_gb / checkpoint_bandwidth_gb_per_sec
    
    <span style="color: #6a9955;"># Samples processed in acceptable rework time</span>
    acceptable_rework_samples = (
        training_throughput_samples_per_sec * acceptable_rework_hours * <span style="color: #b5cea8;">3600</span>
    )
    
    <span style="color: #6a9955;"># Checkpoint every N samples</span>
    checkpoint_interval_samples = acceptable_rework_samples
    
    <span style="color: #6a9955;"># But ensure checkpoint overhead < 5% of training time</span>
    min_interval_seconds = checkpoint_time_seconds * <span style="color: #b5cea8;">20</span>  <span style="color: #6a9955;"># 5% overhead</span>
    min_interval_samples = min_interval_seconds * training_throughput_samples_per_sec
    
    <span style="color: #c586c0;">return</span> max(checkpoint_interval_samples, min_interval_samples)

<span style="color: #6a9955;"># Example: 70B model training</span>
interval = calculate_checkpoint_interval(
    model_size_gb=<span style="color: #b5cea8;">140</span>,           <span style="color: #6a9955;"># 70B params &times; 2 bytes</span>
    training_throughput_samples_per_sec=<span style="color: #b5cea8;">100</span>,  <span style="color: #6a9955;"># 100 samples/sec</span>
    checkpoint_bandwidth_gb_per_sec=<span style="color: #b5cea8;">10</span>,       <span style="color: #6a9955;"># RAID NVMe</span>
    acceptable_rework_hours=<span style="color: #b5cea8;">0.5</span>
)
print(f<span style="color: #ce9178;">"Checkpoint every {interval:,.0f} samples"</span>)
<span style="color: #6a9955;"># Output: Checkpoint every 180,000 samples</span>
<span style="color: #6a9955;"># (about every 30 minutes at 100 samples/sec)</span></code></pre>

        </section>

        <nav class="nav-header" style="margin-top: 50px;">
            <a href="10_expert_storage_guide.html">&larr; Expert Guide</a>
            <span style="color: var(--text-secondary);">ML Frameworks</span>
            <a href="index.html">Home &rarr;</a>
        </nav>

    </div>
</body>
</